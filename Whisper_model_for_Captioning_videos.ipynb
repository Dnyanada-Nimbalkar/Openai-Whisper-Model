{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJJpAx8abXCpzS5E9Xa625",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dnyanada-Nimbalkar/Openai-Whisper-Model/blob/main/Whisper_model_for_Captioning_videos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdiJIbvBgRij",
        "outputId": "2e97d07c-33c8-474f-9284-343166f2a539"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install gradio -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rw8eddT9gq7N",
        "outputId": "ae4d7469-3b72-473a-9abd-0e7da3fdfdc1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.8/298.8 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "#from moviepy.editor import VideoFileClip"
      ],
      "metadata": {
        "id": "217k9nbqhC8R"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def video2mp3(video_file, output_ext=\"mp3\"):\n",
        "    filename, ext = os.path.splitext(video_file)\n",
        "    subprocess.call([\"ffmpeg\", \"-y\", \"-i\", video_file, f\"{filename}.{output_ext}\"],\n",
        "                    stdout=subprocess.DEVNULL,\n",
        "                    stderr=subprocess.STDOUT)\n",
        "    return f\"{filename}.{output_ext}\"\n"
      ],
      "metadata": {
        "id": "HNiu1TkBhDgY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(input_video):\n",
        "\n",
        "    audio_file = video2mp3(input_video)\n",
        "\n",
        "    options = dict(beam_size=5, best_of=5)\n",
        "    translate_options = dict(task=\"translate\", **options)\n",
        "    result = model.transcribe(audio_file,**translate_options)\n",
        "\n",
        "    output_dir = '/content/'\n",
        "    audio_path = audio_file.split(\".\")[0]\n",
        "\n",
        "    with open(os.path.join(output_dir, audio_path + \".vtt\"), \"w\") as vtt:\n",
        "      write_vtt(result[\"segments\"], file=vtt)\n",
        "\n",
        "    subtitle = audio_path + \".vtt\"\n",
        "    output_video = audio_path + \"_subtitled.mp4\"\n",
        "\n",
        "    os.system(f\"ffmpeg -i {input_video} -vf subtitles={subtitle} {output_video}\")\n",
        "\n",
        "    return output_video"
      ],
      "metadata": {
        "id": "OWGi7GsUjLZI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title = \"Add Text/Caption to your YouTube Shorts - MultiLingual\"\n",
        "\n",
        "block = gr.Blocks()\n",
        "\n",
        "with block:\n",
        "\n",
        "    with gr.Group():\n",
        "        with gr.Box():\n",
        "\n",
        "\n",
        "\n",
        "            with gr.Row().style():\n",
        "\n",
        "                inp_video = gr.Video(\n",
        "                    label=\"Input Video\",\n",
        "                    type=\"filepath\",\n",
        "                    mirror_webcam = False\n",
        "                )\n",
        "                op_video = gr.Video()\n",
        "            btn = gr.Button(\"Generate Subtitle Video\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        btn.click(translate, inputs=[inp_video], outputs=[op_video])\n",
        "\n",
        "        gr.HTML('''\n",
        "        <div class=\"footer\">\n",
        "                    <p>Model by <a href=\"https://github.com/openai/whisper\" style=\"text-decoration: underline;\" target=\"_blank\">OpenAI</a> - Gradio App by <a href=\"https://twitter.com/1littlecoder\" style=\"text-decoration: underline;\" target=\"_blank\">1littlecoder</a>\n",
        "                    </p>\n",
        "        </div>\n",
        "        ''')\n",
        "\n",
        "block.launch(debug = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "id": "Gb8fFZKijLiI",
        "outputId": "9f03f603-6f06-4508-e946-7850b1eb3e50"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-7dff018f9ea6>:12: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
            "  with gr.Row().style():\n",
            "<ipython-input-11-7dff018f9ea6>:14: GradioUnusedKwargWarning: You have unused kwarg parameters in Video, please remove them: {'type': 'filepath'}\n",
            "  inp_video = gr.Video(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://de2c5b83daca3bb5a2.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://de2c5b83daca3bb5a2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://de2c5b83daca3bb5a2.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hkyQMNVWjLlR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}